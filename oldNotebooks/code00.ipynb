{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "from IPython.display import display, Audio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_dir = '../../LibriVox_Kaggle/'\n",
    "bg_dir = '../../LibriVox_Kaggle/BGnoise/'\n",
    "rir_dir = '../../RIR/MIT_IR_Survey/Audio/'\n",
    "train_csv_file = 'only_audioFname_train.csv'\n",
    "test_csv_file = 'only_audioFname_test.csv'\n",
    "\n",
    "bg_files = os.listdir(bg_dir)\n",
    "rir_files = os.listdir(rir_dir)[1::]\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "N_FFT = 1024\n",
    "WIN_LEN = 1024\n",
    "HOP_LEN = 256\n",
    "\n",
    "spectrogram = T.Spectrogram(n_fft=N_FFT, \n",
    "                            win_length=WIN_LEN, \n",
    "                            hop_length=HOP_LEN, \n",
    "                            center=True, \n",
    "                            pad_mode=\"reflect\", \n",
    "                            power = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_audio(audio, sr):\n",
    "    resampled_audio = F.resample(audio, sr, SAMPLE_RATE)\n",
    "    return resampled_audio\n",
    "\n",
    "def stereo_to_mono(audio):\n",
    "    new_audio = torch.mean(audio, dim=0).unsqueeze(0)\n",
    "    return new_audio\n",
    "\n",
    "\n",
    "def load_audio(aud_fname):\n",
    "    \n",
    "    raw_wav, sampleRate = torchaudio.load(aud_fname)\n",
    "    if raw_wav.shape[0] == 2:\n",
    "        raw_wav = stereo_to_mono(raw_wav)\n",
    "    if sampleRate != SAMPLE_RATE:\n",
    "        raw_wav = resample_audio(raw_wav, sampleRate)\n",
    "    return raw_wav\n",
    "\n",
    "\n",
    "def add_noise(audio, rir, noise_wav, snr):\n",
    "    echo_audio = F.fftconvolve(audio, rir)[:,0:audio.shape[1]]\n",
    "    noisy_audio = F.add_noise(echo_audio, noise_wav[:,0:audio.shape[1]], torch.Tensor([snr]))\n",
    "    return noisy_audio\n",
    "\n",
    "def random_second_choice(audio):\n",
    "    duration = (int)(audio.shape[1]/SAMPLE_RATE)\n",
    "    random_sec = random.choice([i for i in range(0, duration-1)])\n",
    "    return random_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "\n",
    "    rir_fname = os.path.join(rir_dir,random.choice(rir_files))\n",
    "    bg_fname = os.path.join(bg_dir, random.choice(bg_files))\n",
    "    snr_choice = random.choice([5,10,20])\n",
    "\n",
    "    wav = load_audio(filename)\n",
    "    rir_ = load_audio(rir_fname)\n",
    "    bg = load_audio(bg_fname)\n",
    "\n",
    "    rand_wav_sec = random_second_choice(wav)\n",
    "    rand_bg_sec = random_second_choice(bg)\n",
    "\n",
    "    wav_sec = wav[:,rand_wav_sec*SAMPLE_RATE:(rand_wav_sec+1)*SAMPLE_RATE]\n",
    "    bg_sec = bg[:,rand_bg_sec*SAMPLE_RATE:(rand_bg_sec+1)*SAMPLE_RATE]\n",
    "\n",
    "    noisy_audio = add_noise(wav_sec, rir_, bg_sec, snr_choice)\n",
    "\n",
    "    return noisy_audio, bg_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_inst = T.Spectrogram(\n",
    "    n_fft=400,\n",
    "    win_length=None,\n",
    "    hop_length=100,\n",
    "    power=None\n",
    ")\n",
    "\n",
    "inv_spec_inst = T.InverseSpectrogram(\n",
    "    n_fft=400,\n",
    "    win_length=None,\n",
    "    hop_length=100\n",
    ")\n",
    "\n",
    "def get_spectrogram(audio):\n",
    "    spec = T.Spectrogram(power=None)(audio)\n",
    "    return spec\n",
    "\n",
    "def get_audio_from_spectrogram(spec):\n",
    "    audio = T.InverseSpectrogram()(spec)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spec_image(audio):\n",
    "    \n",
    "    spec = spectrogram(audio.squeeze()).numpy()\n",
    "    fig, axs = plt.subplots()\n",
    "    plt.figure(figsize=(10,4))\n",
    "    img = axs.imshow(librosa.power_to_db(spec), interpolation=\"nearest\", origin=\"lower\", aspect=\"auto\", cmap=\"viridis\")\n",
    "    axs.axis('off')\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    data = data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    pil_image = Image.fromarray(data)\n",
    "    plt.close(fig)\n",
    "    return pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_aud = '../../LibriVox_Kaggle/achtgesichterambiwasse/achtgesichterambiwasse_0009.wav'\n",
    "\n",
    "noisy, noise = get_data(sample_aud)\n",
    "\n",
    "noisy_spec = get_spectrogram(noisy)\n",
    "noisy_aud = get_audio_from_spectrogram(noisy_spec)\n",
    "\n",
    "dada = torch.view_as_real(noisy_spec)\n",
    "reshpd = torch.reshape(dada, (1,2,201,81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class audioDataset(Dataset):\n",
    "\n",
    "    def __init__(self, audio_csvfile, aud_dir):\n",
    "        self.audio_df = pd.read_csv(audio_csvfile)\n",
    "        self.aud_dir = aud_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        audio_path = os.path.join(self.aud_dir, self.audio_df.iloc[index, 0])\n",
    "\n",
    "        audio_in, label = get_data(audio_path)\n",
    "        \n",
    "        audio_spec = torch.view_as_real(get_spectrogram(audio_in))\n",
    "        label_spec = torch.view_as_real(get_spectrogram(label))\n",
    "        audio_spec = torch.reshape(audio_spec,(1,2,201,81))\n",
    "        label_spec = torch.reshape(label_spec, (1,2,201,81))\n",
    "\n",
    "        return audio_spec, label_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "aud_dir = '../../LibriVox_Kaggle/'\n",
    "train_csv_file = 'only_audioFname_train.csv'\n",
    "test_csv_file = 'only_audioFname_test.csv'\n",
    "\n",
    "train_dataset = audioDataset('only_audioFname_train.csv', aud_dir)\n",
    "test_dataset = audioDataset('only_audioFname_test.csv', aud_dir)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 2, 201, 81]), torch.Size([32, 1, 2, 201, 81]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_spec, labs = next(iter(train_dataloader))\n",
    "audio_spec.shape, labs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 201, 81])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "torch.cuda.manual_seed(13)\n",
    "\n",
    "class speechRemoval00(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(speechRemoval00, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(2, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 2, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(13)\n",
    "torch.cuda.manual_seed(13)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = speechRemoval00().to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/work/dpandya/giggityGit/speechRemoval/code00.ipynb Cell 14\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,epochs):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     loss_ten \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor([])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m#print('pass')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m         model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         inputs, labels \u001b[39m=\u001b[39m data\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/noiseremoval/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/noiseremoval/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/noiseremoval/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/noiseremoval/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32m/work/dpandya/giggityGit/speechRemoval/code00.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     audio_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maud_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_df\u001b[39m.\u001b[39miloc[index, \u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     audio_in, label \u001b[39m=\u001b[39m get_data(audio_path)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     audio_spec \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(get_spectrogram(audio_in))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     label_spec \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mview_as_real(get_spectrogram(label))\n",
      "\u001b[1;32m/work/dpandya/giggityGit/speechRemoval/code00.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m rir_ \u001b[39m=\u001b[39m load_audio(rir_fname)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m bg \u001b[39m=\u001b[39m load_audio(bg_fname)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m rand_wav_sec \u001b[39m=\u001b[39m random_second_choice(wav)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m rand_bg_sec \u001b[39m=\u001b[39m random_second_choice(bg)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m wav_sec \u001b[39m=\u001b[39m wav[:,rand_wav_sec\u001b[39m*\u001b[39mSAMPLE_RATE:(rand_wav_sec\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mSAMPLE_RATE]\n",
      "\u001b[1;32m/work/dpandya/giggityGit/speechRemoval/code00.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrandom_second_choice\u001b[39m(audio):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     duration \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m)(audio\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m/\u001b[39mSAMPLE_RATE)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     random_sec \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mchoice([i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m0\u001b[39;49m, duration\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdws-07.informatik.uni-mannheim.de/work/dpandya/giggityGit/speechRemoval/code00.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random_sec\n",
      "File \u001b[0;32m/work/dpandya/miniconda3/envs/noiseremoval/lib/python3.11/random.py:373\u001b[0m, in \u001b[0;36mRandom.choice\u001b[0;34m(self, seq)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39m# As an accommodation for NumPy, we don't use \"if not seq\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39m# because bool(numpy.array()) raises a ValueError.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(seq):\n\u001b[0;32m--> 373\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot choose from an empty sequence\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    374\u001b[0m \u001b[39mreturn\u001b[39;00m seq[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_randbelow(\u001b[39mlen\u001b[39m(seq))]\n",
      "\u001b[0;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "\n",
    "    loss_ten = torch.Tensor([])\n",
    "    for data in train_dataloader:\n",
    "        #print('pass')\n",
    "        model.train()\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.squeeze().to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(outputs, inputs)\n",
    "\n",
    "        # BP and optim\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_ten = torch.cat((loss_ten,torch.Tensor([loss.item()])),0)\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {torch.mean(loss_ten)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noiseremoval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
